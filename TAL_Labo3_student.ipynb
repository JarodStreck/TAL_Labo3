{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 3<br/>*Depedency parser* pour le français dans spaCy\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Évaluer l'analyseur syntaxique en dépendances fourni par spaCy dans le modèle `fr_core_news_sm`, puis le comparer avec un analyseur entraîné par vous-mêmes.  Les données sont les mêmes qu'au Labo 2 et la démarche du labo est similaire aussi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prise en main de l'analyseur de spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\") # charge la pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a.** Pour la pipeline `fr_core_news_sm`, veuillez afficher les traitements disponibles, puis désactiver tous les traitements sauf `tok2vec`, `morphologizer` et `parser`, puis vérifiez que la désactivation a bien fonctionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'morphologizer', 'parser']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "nlp.pipe_names\n",
    "nlp.disable_pipe(\"attribute_ruler\")\n",
    "nlp.disable_pipe(\"lemmatizer\")\n",
    "nlp.disable_pipe(\"ner\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.fr.examples import sentences\n",
    "s1 = sentences[2] # prenons la 3e phrase comme exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b.** Veuillez analyser `s1` avec la pipeline `nlp` puis afficher chaque token, son POS tag, et son étiquette indiquant la relation de dépendance (entre crochets, après le token).  Quelle information essentielle manque dans cette représentation ?\n",
    "\n",
    "Note : le *morphologizer* fournit aussi les POS tags.  La liste des tags possibles est [fournie par spaCy](https://spacy.io/models/fr#fr_core_news_md-labels).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San [DET] [det]\n",
      "Francisco [PROPN] [nsubj]\n",
      "envisage [VERB] [ROOT]\n",
      "d' [ADP] [case]\n",
      "interdire [NOUN] [xcomp]\n",
      "les [DET] [det]\n",
      "robots [NOUN] [obj]\n",
      "coursiers [ADJ] [amod]\n",
      "sur [ADP] [case]\n",
      "les [DET] [det]\n",
      "trottoirs [NOUN] [obl:mod]\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code et votre réponse ici.\n",
    "doc = nlp(s1)\n",
    "for token in doc:\n",
    "    print(token.text + \" [\" + token.pos_ + \"]\" + \" [\" + token.dep_ + \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c.** Veuillez afficher tous les groupes de mots qui sont soit des `nsubj` soit des `obj` dans la phrase `s1` (c'est à dire les sujets et les objets du verbe).   Indication : le sous-arbre d'un token *t* est accessible comme `t.subtree`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Francisco [PROPN] [nsubj]\n",
      "  - San [DET] [det]\n",
      "  - Francisco [PROPN] [nsubj]\n",
      "robots [NOUN] [obj]\n",
      "  - les [DET] [det]\n",
      "  - robots [NOUN] [obj]\n",
      "  - coursiers [ADJ] [amod]\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "for token in doc:\n",
    "    if token.dep_ in [\"nsubj\",\"obj\"]:\n",
    "        print(token.text + \" [\" + token.pos_ + \"]\" + \" [\" + token.dep_ + \"]\")\n",
    "        for subtoken in token.subtree:\n",
    "            print(\"  - \" + subtoken.text + \" [\" + subtoken.pos_ + \"]\" + \" [\" + subtoken.dep_ + \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Évaluation quantitative de l'analyseur sur une phrase \n",
    "\n",
    "Les données sont les mêmes que celles du Labo 2.  Vous les avez déjà transformées au Labo 2 dans un format utilisable par spaCy, dans un dossier nommé `Labo2/spacy_data` que vous allez réutiliser.  Les trois fichiers contiennent des phrases en français annotées aussi avec les arbres de dépendance.  Le fichier `fr-ud-train.conllu` est destiné à l'entraînement, `fr-ud-dev.conllu` au réglage des paramètres, et `fr-ud-test.conllu` à l'évaluation finale.\n",
    "\n",
    "**2a.** En inspectant un des fichiers d'origine avec un éditeur texte, veuillez indiquer dans quelles colonnes se trouvent les informations sur les relations de dépendance, et comment elles sont représentées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre réponse dans cette cellule.\n",
    "# Les informations sur les relations de dépendance se trouvent aux colonnes 8 et 9\n",
    "# La colonne 8 contient la relations de dépendance universelle don la liste se trouve ici : https://universaldependencies.org/u/dep/index.html\n",
    "# La colonne 9 contient un graphe de dépendance amélioré sous la forme d'une liste de paires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin, Doc\n",
    "test_data = DocBin().from_disk(\"./spacy_data/fr-ud-test.spacy\")\n",
    "# for doc in test_data.get_docs(nlp.vocab):  # exemple\n",
    "#     for sent in doc.sents:\n",
    "#         print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b**. On rapplle que les données des fichiers convertis peuvent être chargées dans un objet de type `DocBin`.  Ici, un tel objet contient un ensemble de documents, chacun contenant 10 phrases.  Chaque document est un objet de type `Doc`.  Le code donné ci-dessous vous permet de charger les données de test et vous montre comment les afficher.\n",
    "\n",
    "* Veuillez stocker la *7e phrase du 2e document des données de test* dans une variable nommée `s2`.\n",
    "* Veuillez afficher cette phrase (elle commence par \"Trois ans\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trois ans plus tard, il tient un discours sur la crise.\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "second_doc = list(test_data.get_docs(nlp.vocab))[1]\n",
    "s2 = list(second_doc.sents)[6]  \n",
    "\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** En utilisant `displaCy` comme expliqué [ici](https://spacy.io/usage/visualizers) veuillez afficher graphiquement l'arbre de dépendances de la phrase `s2` tel qu'il est fourni dans les données.  Pour être affichée, la phrase doit être transformée en objet `Doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"62197c55f01f4984a61b3b5e6e0d39b2-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Trois</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NUM</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">ans</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">plus</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">tard,</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">il</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">tient</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">un</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">discours</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">sur</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">la</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
      "</text>\n",
      "\n",
      "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
      "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">crise.</tspan>\n",
      "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
      "</text>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "\n",
      "<g class=\"displacy-arrow\">\n",
      "    <path class=\"displacy-arc\" id=\"arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
      "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
      "        <textPath xlink:href=\"#arrow-62197c55f01f4984a61b3b5e6e0d39b2-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
      "    </text>\n",
      "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
      "</g>\n",
      "</svg>\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "f = open(\"fr-ud-dev_dep_graph.svg\", \"w\")\n",
    "svg = displacy.render(s2, style=\"dep\",jupyter=False)\n",
    "print(svg)\n",
    "f.write(svg)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d.** En utilisant `displaCy`, veuillez également afficher l'arbre de dépendances calculé par la pipeline `nlp` pour cette même phrase `s2`.  Pour être analysée et affichée, la phrase doit être transformée en objet `Doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "doc = nlp(s2.text)\n",
    "f = open(\"nlp_dep_graph.svg\", \"w\")\n",
    "svg = displacy.render(doc, style=\"dep\",jupyter=False)\n",
    "f.write(svg)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2e.** Veuillez comparer les deux arbres de dépendances et indiquer ici les différences.  Quel est le taux de correction de la pipeline `nlp` sur cette phrase ?\n",
    "\n",
    "Suggestion : il peut être utile de sauvegarder les deux arbres dans des images SVG, en écrivant dans un fichier le résultat retourné par `displacy.render` avec l'option `jupyter = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre réponse ici.\n",
    "# On a 10 relations pour la phrase qui vient de fr-ud-dev\n",
    "# On a 2 mots qui n'ont plus la même tête et toutes les autre dépendance ont le bon tag de dépendance\n",
    "# UAS : 8/10 = 80%\n",
    "# LAS 8/10 = 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f.**  Veuillez appliquer le `Scorer` de spaCy (voir Labo 2) et afficher les deux scores qu'il produit pour l'analyse en dépendances (avec trois décimales après la virgule).  Retrouvez-vous les scores de la question précédente ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.training import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS :  0.818\n",
      "LAS :  0.818\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code et votre réponse ici.\n",
    "exemple = Example(s2.as_doc(),doc)\n",
    "score = Scorer().score([exemple])\n",
    "print(\"UAS : \", round(score.get(\"dep_uas\"),ndigits=3))\n",
    "print(\"LAS : \", round(score.get(\"dep_las\"),ndigits=3))\n",
    "\n",
    "# On a un score similaire mais pas exactement le même que calculer a la main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Évaluation du *dependency parser* de `fr_core_news_sm` sur l'ensemble des phrases test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a.** Veuillez calculer les deux scores qui caractérisent l'analyseur en dépendances de la pipeline `nlp` sur toutes les données de test présentes dans `test_data`.  Comment se comparent ces scores avec ceux mentionnés [dans la documentation de fr_core_news_sm](https://spacy.io/models/fr#fr_core_news_sm) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS :  0.814\n",
      "LAS :  0.687\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "ref_docs = test_data.get_docs(nlp.vocab)\n",
    "pred_docs = []\n",
    "exemples = []\n",
    "for doc in test_data.get_docs(nlp.vocab):\n",
    "    pred_docs.append(nlp(doc))\n",
    "\n",
    "for ref_doc, true_doc in zip(ref_docs, pred_docs):\n",
    "    exemple = Example(true_doc,ref_doc)\n",
    "    exemples.append(exemple)\n",
    "    \n",
    "score = Scorer().score(exemples)\n",
    "print(\"UAS : \", round(score.get(\"dep_uas\"),ndigits=3))\n",
    "print(\"LAS : \", round(score.get(\"dep_las\"),ndigits=3))\n",
    "\n",
    "# On a un score un peu en dessous pour l'UAS et nettement inférieur pour le LAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** Le *scorer* fournit également des scores détaillés pour chaque type de relation de dépendances.  Veuillez afficher ces valeurs dans un tableau proprement formaté, trié par score F1 décroissant, avec trois décimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+--------+----------+\n",
      "|     type     | precision | recall | f1 score |\n",
      "+--------------+-----------+--------+----------+\n",
      "|     det      |   0.789   | 0.922  |   0.85   |\n",
      "|     case     |   0.764   | 0.857  |  0.807   |\n",
      "|      cc      |   0.782   | 0.779  |  0.781   |\n",
      "|   aux:pass   |   0.925   | 0.645  |   0.76   |\n",
      "|     mark     |   0.792   | 0.715  |  0.752   |\n",
      "|     cop      |   0.748   | 0.727  |  0.738   |\n",
      "|    nummod    |   0.679   |  0.76  |  0.717   |\n",
      "|    nsubj     |   0.676   | 0.738  |  0.706   |\n",
      "|     root     |   0.776   | 0.635  |  0.698   |\n",
      "|  nsubj:pass  |   0.82    | 0.603  |  0.695   |\n",
      "|    advmod    |    0.7    | 0.657  |  0.678   |\n",
      "|     amod     |   0.728   |  0.6   |  0.658   |\n",
      "|     obj      |   0.661   | 0.636  |  0.648   |\n",
      "|  flat:name   |   0.579   | 0.617  |  0.597   |\n",
      "|    xcomp     |   0.642   |  0.45  |  0.529   |\n",
      "|     nmod     |   0.53    | 0.501  |  0.515   |\n",
      "|  acl:relcl   |   0.52    | 0.459  |  0.488   |\n",
      "|    ccomp     |   0.381   |  0.49  |  0.429   |\n",
      "|    fixed     |   0.32    | 0.625  |  0.423   |\n",
      "|    advcl     |   0.412   | 0.368  |  0.389   |\n",
      "|     conj     |   0.367   | 0.412  |  0.388   |\n",
      "|     acl      |   0.384   | 0.353  |  0.368   |\n",
      "|    appos     |   0.274   | 0.508  |  0.356   |\n",
      "|     iobj     |   0.48    | 0.273  |  0.348   |\n",
      "|   obl:mod    |    0.0    |  0.0   |   0.0    |\n",
      "|     dep      |    0.0    |  0.0   |   0.0    |\n",
      "|  aux:tense   |    0.0    |  0.0   |   0.0    |\n",
      "|   obl:arg    |    0.0    |  0.0   |   0.0    |\n",
      "|  obl:agent   |    0.0    |  0.0   |   0.0    |\n",
      "|  expl:comp   |    0.0    |  0.0   |   0.0    |\n",
      "|  parataxis   |    0.0    |  0.0   |   0.0    |\n",
      "|     obl      |    0.0    |  0.0   |   0.0    |\n",
      "|     aux      |    0.0    |  0.0   |   0.0    |\n",
      "|     expl     |    0.0    |  0.0   |   0.0    |\n",
      "|  expl:subj   |    0.0    |  0.0   |   0.0    |\n",
      "|  obj:agent   |    0.0    |  0.0   |   0.0    |\n",
      "|   aux:caus   |    0.0    |  0.0   |   0.0    |\n",
      "|  nsubj:caus  |    0.0    |  0.0   |   0.0    |\n",
      "|   compound   |    0.0    |  0.0   |   0.0    |\n",
      "|  expl:pass   |    0.0    |  0.0   |   0.0    |\n",
      "|  iobj:agent  |    0.0    |  0.0   |   0.0    |\n",
      "|  discourse   |    0.0    |  0.0   |   0.0    |\n",
      "| flat:foreign |    0.0    |  0.0   |   0.0    |\n",
      "|    csubj     |    0.0    |  0.0   |   0.0    |\n",
      "+--------------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "# Notre score UAS est un peut plus bas que le score metionné dans la documentation qui est de 0.89.\n",
    "# Notre score LAS est bien plus bas que le score mentionné dans la documentation qui est de 0.86.\n",
    "\n",
    "# print each score decreasing order\n",
    "from itertools import *\n",
    "from tabulate import tabulate\n",
    "\n",
    "sortedItems = sorted(score['dep_las_per_type'].items(), key=lambda x: x[1]['f'], reverse=True)\n",
    "\n",
    "flat_list = []\n",
    "for key in sortedItems:\n",
    "    tmp = []\n",
    "    tmp.append(key[0])\n",
    "    for el in key[1]:\n",
    "        tmp.append(round(key[1].get(el), ndigits=3))\n",
    "    flat_list.append(tmp)\n",
    "\n",
    "print(tabulate(flat_list, headers=[\"type\", \"precision\", \"recall\", \"f1 score\"], tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entraîner puis évaluer un nouveau *parser* français dans spaCy\n",
    "\n",
    "Le but de cette partie est d'entraîner une pipeline spaCy pour le français sur les données de `fr-ud-train.conllu`, puis de comparer le modèle obtenu avec le modèle prêt-à-l'emploi testé au point précédent (voir le Labo 2 et les [instructions de spaCy](https://spacy.io/usage/training#quickstart)).\n",
    "\n",
    "**4a.** Paramétrage de l'entraînement :\n",
    "* générez un fichier de départ grâce à [l'interface web](https://spacy.io/usage/training#quickstart), en indiquant que vous gardez seulement les composants `morphologizer` et `parser` dans la pipeline ;\n",
    "* sauvegardez le code généré par spaCy dans un fichier local `base_config.cfg` ;\n",
    "* générez un fichier `config.cfg` sur votre ordinateur en exécutant la ligne de commande suivante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez effectuer l'entraînement avec la ligne de commande suivante.  Faites plusieurs essais, d'abord avec un petit nombre d'époques (*à indiquer dans config.cfg*), pour estimer le temps nécessaire et observer les messages affichés.  Augmentez progressivement le nombre d'époques, jusqu'à ce que les scores sur le jeu de validation n'augmentent plus (si vous avez le temps).  Pendant combien d'époques entraînez-vous au final ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: myDEPparser1\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'morphologizer', 'parser']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS MORPH...  LOSS PARSER  POS_ACC  MORPH_ACC  DEP_UAS  DEP_LAS  SENTS_F  SCORE \n",
      "---  ------  ------------  -------------  -----------  -------  ---------  -------  -------  -------  ------\n",
      "  0       0          0.00         224.53       504.38    47.23      44.49    12.55     6.00     0.00    0.28\n",
      "  0     200       1653.11       10636.25     32623.23    92.43      91.53    78.10    72.35    76.18    0.84\n",
      "  0     400       2175.49        5004.50     22669.73    92.98      92.63    80.29    74.95    74.58    0.85\n",
      "  0     600       2223.24        4101.18     20069.21    93.29      92.87    81.83    77.07    89.98    0.86\n",
      "  0     800       2502.86        4078.24     19968.86    93.52      93.08    83.04    78.66    91.60    0.87\n",
      "  0    1000       2413.72        3531.29     17707.64    93.57      93.40    83.22    78.94    95.33    0.87\n",
      "  0    1200       2502.77        3382.89     17221.72    93.76      93.55    83.10    79.05    91.47    0.87\n",
      "  0    1400       2763.95        3228.21     17187.72    93.68      93.44    83.05    78.96    92.51    0.87\n",
      "  1    1600       2693.71        2853.66     16023.18    93.86      93.63    84.08    79.76    95.20    0.88\n",
      "  1    1800       2905.24        2721.97     15276.50    93.76      93.65    84.47    80.44    94.05    0.88\n",
      "  1    2000       3106.16        2878.03     15268.69    93.96      93.75    84.74    81.02    94.53    0.88\n",
      "  1    2200       3312.71        2684.85     15302.48    94.06      93.81    84.92    81.13    95.37    0.88\n",
      "  1    2400       3531.29        2819.49     15300.50    93.99      93.79    84.52    81.10    95.13    0.88\n",
      "  1    2600       3817.72        2843.43     15929.72    94.06      93.83    85.11    81.49    95.64    0.89\n",
      "  1    2800       3967.27        2838.18     15799.56    94.09      93.85    85.34    81.51    95.40    0.89\n",
      "  2    3000       4075.43        2731.67     15216.96    94.11      93.92    85.20    81.64    95.64    0.89\n",
      "  2    3200       4030.01        2165.60     13654.68    94.26      94.07    85.51    82.05    95.74    0.89\n",
      "  2    3400       4426.11        2394.67     14079.79    94.04      93.94    85.59    82.21    95.80    0.89\n",
      "  2    3600       4563.14        2468.26     14040.00    94.13      94.01    85.11    81.60    95.75    0.89\n",
      "  2    3800       4494.55        2336.53     13733.90    94.14      93.85    85.41    81.52    95.54    0.89\n",
      "  2    4000       4609.54        2211.69     13661.71    94.04      93.91    85.88    82.59    95.55    0.89\n",
      "  2    4200       4727.70        2299.38     13662.24    94.24      94.03    85.79    82.29    95.52    0.89\n",
      "  3    4400       4831.79        2277.16     13396.01    94.28      94.16    85.89    82.83    95.49    0.89\n",
      "  3    4600       5086.10        2027.03     13324.26    94.11      93.94    85.65    82.44    96.10    0.89\n",
      "  3    4800       5279.01        2009.38     12676.45    94.20      94.01    85.66    82.38    95.90    0.89\n",
      "  3    5000       5654.53        2031.86     12923.45    94.22      94.10    85.55    82.41    95.32    0.89\n",
      "  3    5200       5738.29        1997.29     13057.59    94.21      94.07    86.09    82.67    95.95    0.89\n",
      "  3    5400       5682.68        2019.01     12769.86    94.13      94.03    85.72    82.33    95.48    0.89\n",
      "  3    5600       5822.95        2105.68     12659.32    94.11      94.08    85.79    82.55    95.71    0.89\n",
      "  3    5800       6085.09        2097.08     12890.72    94.24      94.07    86.39    82.86    95.74    0.89\n",
      "  4    6000       5812.51        1655.45     11674.18    94.22      94.08    86.35    83.27    95.92    0.89\n",
      "  4    6200       6558.26        1834.49     11873.92    94.14      94.00    86.25    82.88    96.42    0.89\n",
      "  4    6400       6492.46        1720.12     11623.27    94.19      94.03    86.02    82.78    95.78    0.89\n",
      "  4    6600       7049.04        1898.86     12348.50    94.21      94.07    86.07    82.87    96.40    0.89\n",
      "  4    6800       7067.56        1783.26     12121.40    94.24      94.15    86.25    83.06    96.81    0.89\n",
      "  4    7000       7137.91        1898.81     12239.64    94.25      94.09    85.61    82.61    96.20    0.89\n",
      "  4    7200       7241.95        1804.32     12104.72    94.24      94.11    86.54    83.23    96.11    0.90\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "myDEPparser1\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "[2024-03-28 20:43:00,400] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "[2024-03-28 20:43:03,450] [INFO] Set up nlp object from config\n",
      "[2024-03-28 20:43:03,463] [DEBUG] Loading corpus from path: spacy_data\\fr-ud-dev.spacy\n",
      "[2024-03-28 20:43:03,465] [DEBUG] Loading corpus from path: spacy_data\\fr-ud-train.spacy\n",
      "[2024-03-28 20:43:03,465] [INFO] Pipeline: ['tok2vec', 'morphologizer', 'parser']\n",
      "[2024-03-28 20:43:03,468] [INFO] Created vocabulary\n",
      "[2024-03-28 20:43:05,927] [INFO] Added vectors: fr_core_news_lg\n",
      "[2024-03-28 20:43:05,927] [INFO] Finished initializing nlp object\n",
      "[2024-03-28 20:43:28,429] [INFO] Initialized pipeline components: ['tok2vec', 'morphologizer', 'parser']\n",
      "[2024-03-28 20:43:28,442] [DEBUG] Loading corpus from path: spacy_data\\fr-ud-dev.spacy\n",
      "[2024-03-28 20:43:28,443] [DEBUG] Loading corpus from path: spacy_data\\fr-ud-train.spacy\n",
      "[2024-03-28 20:43:28,503] [DEBUG] Removed existing output directory: myDEPparser1\\model-best\n",
      "[2024-03-28 20:43:28,565] [DEBUG] Removed existing output directory: myDEPparser1\\model-last\n"
     ]
    }
   ],
   "source": [
    "# Note : il vaut mieux exécuter cela directement dans une fenêtre de commande, pour voir les logs en temps réel.\n",
    "!python -m spacy train config.cfg \\\n",
    "  --output ./myDEPparser1 \\\n",
    "  --paths.train ./spacy_data/fr-ud-train.spacy \\\n",
    "  --paths.dev ./spacy_data/fr-ud-dev.spacy \\\n",
    "  --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez indiquer ici le nombre d'époques final.\n",
    "# Nous avons  fait un entrainement avec le nombre d'epoch max a 0 et nous l'avons laissé tourner pendant 127 minutes.\n",
    "# L'emtrainement a ete fait sur 10 epochs, mais on peut voir qu'apres 5 epochs nous avons un score de 0.90 qui ne s'ameliore plus les epchoch suivantes.\n",
    "# Nous pouvons donc arreter l'entrainement a 5 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b.**  Veuillez charger le meilleur modèle (pipeline) dans la variable `nlp2` et afficher ses scores sur les données de test.  Comment se comparent les résultats avec les précédents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS :  0.878\n",
      "LAS :  0.822\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "\n",
    "# Chagement du model\n",
    "nlp2 = spacy.load(\"./myDEPparser1/model-best\")\n",
    "\n",
    "# Chargement du test data\n",
    "test_data_path = \"./spacy_data/fr-ud-test.spacy\"\n",
    "test_docs = list(DocBin().from_disk(test_data_path).get_docs(nlp2.vocab))\n",
    "\n",
    "scorer2 = Scorer()\n",
    "examples = []\n",
    "\n",
    "# Prediction des tags pour chaque document\n",
    "for doc in test_docs:\n",
    "    doc_pred = nlp2(doc.text)\n",
    "    example = Example(doc, doc_pred)\n",
    "    examples.append(example)\n",
    "\n",
    "score2 = scorer2.score(examples)\n",
    "print(\"UAS : \", round(score2.get(\"dep_uas\"),ndigits=3))\n",
    "print(\"LAS : \", round(score2.get(\"dep_las\"),ndigits=3))\n",
    "\n",
    "# On vois que le score est meilleur que le score optenu precedament.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Veuillez afficher les scores détaillés pour chaque type de relation de dépendances, dans un tableau formaté comme au 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------+----------+\n",
      "|    type    | precision | recall | f1 score |\n",
      "+------------+-----------+--------+----------+\n",
      "|  aux:caus  |    1.0    |  1.0   |   1.0    |\n",
      "|    case    |   0.951   | 0.927  |  0.939   |\n",
      "|    aux     |   0.846   |  0.96  |   0.9    |\n",
      "|    root    |   0.884   | 0.904  |  0.894   |\n",
      "|     cc     |   0.883   | 0.883  |  0.883   |\n",
      "|    det     |   0.808   | 0.972  |  0.882   |\n",
      "|   nsubj    |   0.871   | 0.882  |  0.877   |\n",
      "|    cop     |   0.892   | 0.861  |  0.876   |\n",
      "|    mark    |   0.874   | 0.867  |  0.871   |\n",
      "|    obj     |   0.922   | 0.821  |  0.868   |\n",
      "|    amod    |   0.874   | 0.858  |  0.866   |\n",
      "|   advmod   |   0.83    | 0.807  |  0.819   |\n",
      "|   xcomp    |   0.792   |  0.84  |  0.816   |\n",
      "| nsubj:pass |   0.92    | 0.719  |  0.807   |\n",
      "| nsubj:caus |    0.8    |  0.8   |   0.8    |\n",
      "|    nmod    |   0.824   | 0.753  |  0.787   |\n",
      "|   nummod   |    0.8    | 0.772  |  0.786   |\n",
      "|  aux:pass  |   0.925   | 0.671  |  0.778   |\n",
      "| flat:name  |   0.825   | 0.723  |   0.77   |\n",
      "|    obl     |   0.722   | 0.738  |   0.73   |\n",
      "|    acl     |   0.68    | 0.702  |  0.691   |\n",
      "|   ccomp    |   0.603   | 0.792  |  0.685   |\n",
      "|   advcl    |   0.696   |  0.64  |  0.667   |\n",
      "| acl:relcl  |   0.667   | 0.649  |  0.658   |\n",
      "|    iobj    |   0.68    |  0.63  |  0.654   |\n",
      "|    conj    |   0.645   | 0.645  |  0.645   |\n",
      "|   fixed    |   0.459   | 0.878  |  0.603   |\n",
      "| obj:agent  |   0.429   |  1.0   |   0.6    |\n",
      "|    expl    |   0.446   | 0.833  |  0.581   |\n",
      "|   appos    |   0.564   | 0.426  |  0.485   |\n",
      "|  compound  |   0.195   | 0.533  |  0.286   |\n",
      "| parataxis  |   0.125   | 0.182  |  0.148   |\n",
      "|    dep     |    0.0    |  0.0   |   0.0    |\n",
      "| iobj:agent |    0.0    |  0.0   |   0.0    |\n",
      "| obl:agent  |    0.0    |  0.0   |   0.0    |\n",
      "| discourse  |    0.0    |  0.0   |   0.0    |\n",
      "|   csubj    |    0.0    |  0.0   |   0.0    |\n",
      "+------------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "# precedent UAS :  0.814\n",
    "# prededent LAS :  0.687\n",
    "\n",
    "from itertools import *\n",
    "from tabulate import tabulate\n",
    "\n",
    "sortedItems2 = sorted(score2['dep_las_per_type'].items(), key=lambda x: x[1]['f'], reverse=True)\n",
    "\n",
    "flat_list2 = []\n",
    "for key in sortedItems2:\n",
    "    tmp = []\n",
    "    tmp.append(key[0])\n",
    "    for el in key[1]:\n",
    "        tmp.append(round(key[1].get(el), ndigits=3))\n",
    "    flat_list2.append(tmp)\n",
    "\n",
    "\n",
    "print(tabulate(flat_list2, headers=[\"type\", \"precision\", \"recall\", \"f1 score\"], tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d.** Quels changements observez-vous en haut (3 premiers labels) et en bas du classement ?  Voyez-vous un label pour lequel les scores n'augmentent pas avec le parser entraîné ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut voir que pour la plus part des labels, les scores ont augmenté. \n",
    "# C'est le cas pour les 3 premiers labels qui ont un score de 1.0 pour le f1 score.  Mais les 3 derniers restent a 0.0.\n",
    "# Il est a note qu'il ya aussi moin de labes avec un score de 0.0.\n",
    "# On peut voir par example que le score des labels cjsubj, discourse, obl:agent n'ont pas augementé et sont reste a 0.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin du Labo.** Veuillez nettoyer ce notebook en gardant seulement les résultats désirés, l'enregistrer, et le soumettre comme devoir sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
